\section{Multidimensional scaling}

\frame{\sectionpage}
## Multidimensional Scaling


* Have distances between individuals.

* Want to draw a picture (map) in 2 dimensions showing
individuals so that distances (or order of distances) as close
together as possible. (Or maybe 3 with `rgl`.)

* If want to preserve actual distances, called {\em metric
multidimensional scaling} (in R, `cmdscale`).

* If only want to preserve order of distances, called {\em
non-metric multidimensional scaling} (in R, `isoMDS` in
package `MASS`).

* Metric scaling has solution that can be worked out exactly.

* Non-metric only has iterative solution.

* Assess quality of fit, see whether use of resulting map is
reasonable. (Try something obviously 3-dimensional and assess its
failure.)




## Packages
The usual, plus a new one:
```{r size="footnotesize", message=F}
library(MASS)
library(tidyverse)
library(ggrepel)
library(ggmap)
library(shapes)
```

   

## Metric scaling: European cities

CSV file `europe.csv` contains road distances (in km) between 16 European cities. Can we reproduce a map of Europe from these distances?

Read in data:

```{r include=F}
options(width = 65)
```

 

```{r size="scriptsize"}
my_url <- "http://www.utsc.utoronto.ca/~butler/d29/europe.csv"
europe <- read_csv(my_url)
```

 


## The data
```{r size="scriptsize"}
europe
```

   

## Multidimensional scaling


* Create distance object first using all but first column of
`europe`. `europe` has distances in it already, so make
into `dist` with `as.dist`.

* Then run multidimensional scaling and look at result:
```{r }
europe.d <- europe %>% select(-1) %>% as.dist()
europe.scale <- cmdscale(europe.d)
head(europe.scale)
```

   


* This is a `matrix` of $x$ and $y$ coordinates.



## As a data frame; make picture
We know how to plot data frames, so make one first.  
```{r size="scriptsize"}
europe_coord <- europe.scale %>%
  as_tibble() %>%
  mutate(city = europe$City) %>%
  print(n = 12)
g <- ggplot(europe_coord, aes(x = V1, y = V2, label = city)) +
  geom_point() + geom_text_repel()
```

   


## The map
```{r fig.height=3.6}
g
```

   


## Making a function


* Idea: given input distance matrix (as stored in a CSV file),
output a map (like the one on the previous page).
```{r size="footnotesize"}
mds_map <- function(filename) {
  x <- read_csv(filename)
  dist <- x %>%
    select_if(is.numeric) %>%
    as.dist()
  x.scale <- cmdscale(dist) # this is a matrix
  x_coord <- x.scale %>%
    as_tibble() %>%
    mutate(place = row.names(x.scale))
  ggplot(x_coord, aes(x = V1, y = V2, label = place)) +
    geom_point() + geom_text_repel() +
    coord_fixed()
}
```

     


* Use `select_if` to pick out all the numerical columns
(no text), whichever they are.

* `x.scale` is matrix with no column headers. Turn into
data frame, acquires headers `V1` and `V2`.

* Get place names from `cmdscale` output.



## Does it work?
```{r fig.height=4, message=F}
mds_map("europe.csv")
```

   


## A square
\begin{multicols}{2}


* The data, in `square.csv`:
\begin{small}

```

x,A  ,B  ,C  ,D
A,0  ,1  ,1  ,1.4
B,1  ,0  ,1.4,1
C,1  ,1.4,0  ,1
D,1.4,1  ,1  ,0

```

\end{small}

* The map (on right):
```{r message=F,fig.height=3,fig.width=3}
mds_map("square.csv")
```

       

\end{multicols}

## Drawing a map of the real Europe


* Works with package `ggmap`.

* First find latitudes and longitudes of our cities, called
*geocoding*:
```{r cache=T,size="small",message=F, eval=F}
latlong <- geocode(europe$City)
latlong <- bind_cols(city = europe$City, latlong)
latlong %>% print(n = 6)
```
$ %$ %$

```{r echo=F,size="small"}
latlong <- readRDS("euro_latlong.rds")
latlong %>% print(n = 6)
```

 


* Just so you know, there is a limit
of 2500 queries per day (it queries Google Maps).



## Making the map


* Get a map of Europe from Google Maps (specify what you want a
map of any way you can in Google Maps). This one centres the map
on the city shown and zooms it so all the cities appear (I had to
experiment):
```{r eval=F}
map <- get_map("Memmingen DE", zoom = 5)
```

     

```{r echo=F}
map <- readRDS("memmingen.rds")
```

 

* Plot the map with `ggmap`. This is `ggplot`,
so add anything to it that you would
add to a `ggplot`, such as cities we want to show:
```{r }
g2 <- ggmap(map) +
  geom_point(
    data = latlong, aes(x = lon, y = lat),
    shape = 3, colour = "red"
  )
```

   


* We don't have a default data frame or `aes` for our
`geom_point`, so have to specify one.



## The real Europe with our cities
```{r fig.height=3.6}
g2
```

   


## Compare our scaling map
```{r fig.height=4,echo=F}
g
```

   

## Comments


* North-south not quite right: Edinburgh and Copenhagen on same
latitude, also Amsterdam and Berlin; Athens should be south of Rome.

* Rotating clockwise by about 45 degrees should fix that.

* General point: MDS only uses distances, so answer can be
"off" by rotation (as here) or reflection (flipping over, say
exchanging west and east while leaving north and south same). 
 


## Exploring the map by plotting in 3 dimensions


* Package `rgl` makes 3D plots.

* We have to fake up a 3rd dimension (by setting all its values
to 1).

* Try this code:
```{r eval=F}
library(rgl)
es.2 <- cbind(europe.scale, 1)
plot3d(es.2, zlim = c(-1000, 1000))
text3d(es.2, text = d$city)
```

     

* Opens a graphics window with the cities plotted and named.

* Click and hold left mouse button to rotate plot. "Rotate away"
3rd dimension to get a possible map (that preserves distances). 


## Ontario, the same way
\ldots using our function:

```{r message=F,fig.height=4}
g <- mds_map("ontario-road-distances.csv")
g
```

   

Thunder Bay and Sault Ste Marie dominate the picture since they are
so far away from everywhere else.
 <<ontario>>=
 ontario=read.csv("ontario-road-distances.csv",header=T)
 ontario.d=as.dist(ontario)
 ontario.scale=cmdscale(ontario.d)
 d=data.frame(ontario.scale,city=colnames(ontario))
 g=ggplot(d,aes(x=X1,y=X2,label=city))+
   geom_point()+coord_fixed()+
   geom_text_repel()
 @ 
 

## Removing points


* Messy: have to find which rows and columns contain
those cities, then remove just those rows and columns.

* Better: 


* "tidy" the distance matrix

* then remove rows we don't need

* then "untidy" it again

* save into .csv file


* Illustrate with square data first (easier to see).



## Square data
```{r message=F}
my_url <- "http://www.utsc.utoronto.ca/~butler/d29/square.csv"
square <- read_csv(my_url)
square
```

   


## Make tidy
```{r size="footnotesize"}
square %>% gather(point, distance, -1)
```

   


## Remove all references to point C
In column `x` or `point`:
```{r }
square %>%
  gather(point, distance, -1) %>%
  filter(x != "C", point != "C")
```

   


## Put back as distance matrix
and save as .csv when we are happy:
```{r }
noc <- square %>%
  gather(point, distance, -1) %>%
  filter(x != "C", point != "C") %>%
  spread(point, distance)
noc
noc %>% write_csv("no-c.csv")
```

   


## Make map of square-without-C
```{r message=F,fig.height=4}
mds_map("no-c.csv")
```

   


## Back to Ontario
```{r fig.height=4}
g
```

   

Get rid of Thunder Bay and Sault Ste Marie.


## Tidy, remove, untidy
```{r message=F,size="footnotesize"}
my_url <- "http://www.utsc.utoronto.ca/~butler/d29/ontario-road-distances.csv"
ontario2 <- read_csv(my_url) %>%
  gather(place, distance, -1) %>%
  filter(
    x != "Thunder Bay",
    place != "Thunder Bay",
    x != "Sault Ste Marie",
    place != "Sault Ste Marie"
  ) %>%
  spread(place, distance) %>%
  write_csv("southern-ontario.csv")
```

   


## Map of Southern Ontario
```{r fig.height=4, message=F}
g <- mds_map("southern-ontario.csv")
g
```

   

Came out geographically about right.


## What about that cluster of points?


* Plot looks generally good, but what about that cluster of points?

* "Zoom in" on area between $-150$ and $-100$ on $x$ axis, $-50$ to 0 on
$y$ axis.

* Code below overrides the `coord_fixed` we had before.

```{r zoom, size="small"}
g2 <- g + coord_fixed(xlim = c(-150, -100), ylim = c(-50, 0))
```

 


## Zoomed-in plot
Ignore the arrows to points off the map:
```{r spal,fig.height=3.5}
g2
```

   



## Does that make sense?


* Get a Google map of the area, with the points labelled.

* First geocode the cities of interest:
```{r message=F, size="footnotesize",cache=T, eval=F}
cities <- c(
  "Kitchener ON", "Hamilton ON", "Niagara Falls ON",
  "St Catharines ON", "Brantford ON"
)
latlong <- geocode(cities)
latlong <- bind_cols(city = cities, latlong) %>% print()
```

     

```{r echo=F}
latlong <- readRDS("ontario_trouble.rds")
latlong %>% print()
```

 


* Get a Google map of the area (experiment with zoom):
```{r message=F, eval=F}
map <- get_map("Hamilton ON", zoom = 8)
```
 get from file

```{r echo=F}
map <- readRDS("hamilton_map.rds")
```

 


* Plot map with cities marked.



## Making the Google map
Plot the map, plus the cities, plus labels for the cities:
```{r }
gmap <- ggmap(map) +
  geom_point(
    data = latlong,
    aes(x = lon, y = lat),
    shape = 3, colour = "red"
  ) +
  geom_text_repel(
    data = latlong,
    aes(label = city)
  )
```

   


\begin{frame}[frame]{The `mds` map and Google map}
\begin{multicols}{2}
```{r fig.height=5.5}
g2
```

     

```{r fig.height=5.5, warning=F}
gmap
```

 
\end{multicols}
St Catharines and Niagara Falls should be the *other* side of
Hamilton! 


## Quality of fit


* Read in "southern Ontario" data set from file:
```{r message=F}
my_url <- "http://www.utsc.utoronto.ca/~butler/d29/southern-ontario.csv"
ontario2 <- read_csv(my_url)
```

     

* Calling `cmdscale` with `eig=T` gives more info:

```{r size="footnotesize"}
ontario2.2 <- ontario2 %>%
  select_if(is.numeric) %>%
  cmdscale(eig = T)
names(ontario2.2)
ontario2.2$GOF
ontario2.3 <- ontario2 %>%
  select_if(is.numeric) %>%
  cmdscale(3, eig = T)
ontario2.3$GOF
```

   




## Comments


* Coordinates now in `points`.

* `GOF` is R-squared-like measure saying how well map
distances match real ones. Higher is better.

* For Ontario road distances, `GOF` better for 3 dimensions
than 2, presumably to accommodate St Catharines and Niagara Falls?



## 3-dimensional coordinates, cities attached
```{r size="scriptsize"}
ontario2.3$points %>%
  as_tibble() %>%
  mutate(city = ontario2$x)
```

   


## RGL code for 3 dimensions
```{r eval=F}
library(rgl)
plot3d(ontario.3)
text3d(ontario.3, text = d2$city)
```

 


\begin{frame}[fragile]{Comparing MDS solution with "reality":
Procrustes rotation}


* How to tell that an MDS map makes a good correspondence with ``what
should be''?

* Problem: MDS map might be rotated/scaled/reflected from reality.

* How to find rotation/scaling/reflection that best matches reality?

* Answer: **Procrustes rotation**.

* In R: `procOPA` in package `shapes`.



## "True" coordinates


* Get latitudes and longitudes of cities by geocoding, as
before. Glue "ON" onto city names to make sure we get right ones:
```{r size="footnotesize", message=F, cache=T, eval=F}
lookup <- str_c(ontario2$x, " ON")
latlong <- geocode(lookup)
latlong <- bind_cols(city = ontario2$x, latlong) %>% print(n = 4)
```

     

```{r echo=F, size="footnotesize"}
latlong <- readRDS("ontario_all.rds")
latlong %>% print(n = 4)
```

 

* Not $(x,y)$ coordinates: one degree of latitude is always
110.25 km, but one degree of longitude is only that at the equator
(less than that as you move further north, down to 0 km at north
pole).


## "True" coordinates part 2


* Make coordinates by multiplying by cosine of "typical" latitude.

* Find mean latitude:
```{r }
m <- mean(latlong$lat)
m
```

     


* Turn into radians and find its cosine:
```{r }
mult <- cos(m * pi / 180)
mult
```

   


* Create "true" coords by multiplying the longitudes by
that. This needs to be R `matrix`, not data frame:
```{r size="footnotesize"}
truecoord <- with(latlong, cbind(V1 = lon * mult, V2 = lat))
```

   


## Using `procOPA`


* Feed 2 things into `procOPA`: first, "true"
coordinates, second MDS coordinates.

* Get out: 


*     (centred and scaled) first set of coordinates `Ahat`

* (centred and scaled) second set of coordinates `Bhat`

* sum of squared differences between two sets of coordinates `OSS`

* Rotation matrix `R`


* `Ahat` and `Bhat` coordinates supposed to
match as well as possible.
```{r message=F,size="footnotesize"}
ontario.pro <- procOPA(
  truecoord,
  ontario2.2$points
)
names(ontario.pro)
```

     


## Make data frames of output, glue together


* Two sets of coordinates, `Ahat` are actual,
`Bhat` are from MDS.
```{r size="scriptsize"}
A <- ontario.pro$Ahat %>%
  as_tibble() %>%
  mutate(which = "actual", city = ontario2$x)
B <- ontario.pro$Bhat %>%
  as_tibble() %>%
  mutate(which = "MDS", city = ontario2$x)
dp <- bind_rows(A, B)
dp %>% sample_n(6)
```
 ## `procOPA, part 2: plotting`
 
   
     
* Make data frames of each, glue together:
 <<size="small",warning=F>>=
 A=with(ontario.pro,data.frame(x=Ahat[,1],
   y=Ahat[,2],which="actual",city=ontario2$x)) 
 B=with(ontario.pro,data.frame(x=Bhat[,1],
   y=Bhat[,2],which="MDS",city=ontario2$x))
 dp=bind_rows(A,B)
 dp %>% sample_n(6)
 @   
 
   
 

## Procrustes rotation plot


* Strategy: plot all the locations, and colour them by whether
they were the true location (red) or the MDS one (blue), which is
in `which`. Label each location with the city name in the
appropriate colour.

* I realized it
was actually easy to join the two instances of a city by a line
(in green, here, 3rd line) by setting `group=city`:
```{r size="footnotesize"}
g_opa <- ggplot(dp, aes(
  x = V1, y = V2, colour = which,
  label = city
)) + geom_point() +
  geom_line(aes(group = city), colour = "green") +
  geom_text_repel(size = 2)
```

     

* On plot, look to see whether points that are same city are
joined by a short green line (good) or a long one (bad).



## The maps
```{r prosesto,echo=F,fig.height=4}
g_opa
```
  
![](bMDS-ont-proc.png)



## Comments


* True locations red, MDS locations blue

* Most things in roughly right place (esp.\ relative to other things)

* Extreme cities off by a bit, but OK relative to neighbours.

* St Catharines, Niagara Falls off by most.

* Sarnia, Windsor also off noticeably.

* These four cities had largest "third dimension" in 3D
representation  `ontario2.3`.



## Rotation matrix
Shows how MDS map needs to be rotated to get best match with actual coordinates:
```{r }
ontario.pro$R
```

   

Rotation angle $\theta$ such that $\cos\theta=0.885$,
$\sin\theta=0.466$: $\theta=23$ degrees (counterclockwise). 
$ %$ %$


## Is that right? Look at MDS map again
```{r fig.height=4}
g
```

   

23 degrees counterclockwise seems about right.


## A cube

```

a-----b
|\    |\
| c---- d
| |   | |
e-|---f |
\|    \|
g-----h

```


Cube has side length 1, so distance across diagonal on same face is $\sqrt{2}\simeq 1.4$ and "long" diagonal of cube is $\sqrt{3}\simeq 1.7$. 
\vspace{3ex}

Try MDS on this obviously 3-dimensional data.



## Cube data as distances
```{r f, message=F, size="footnotesize"}
my_url <- "http://www.utsc.utoronto.ca/~butler/d29/cube.txt"
cube <- read_delim(my_url, " ")
cube
```

   


## Making `dist object`
```{r cuby}
cube.d <- cube %>% select(-1) %>% as.dist()
cube.d
```

 



## MDS and plotting commands


*   By default in 2 dimensions; save the extra stuff for later:

```{r }
cube.2 <- cube.d %>% cmdscale(eig = T)
```

   


* Make data frame to plot, remembering the points to plot are in
`points` now:
```{r }
d <- cube.2$points %>%
  as_tibble() %>%
  mutate(corners = cube$x)
```

   

* Plot points labelled by our names for the corners:
```{r }
g <- ggplot(d, aes(x = V1, y = V2, label = corners)) +
  geom_point() + geom_text_repel()
```

   


## The "cube"
```{r bianconeri,echo=F,fig.height=4}
g
```

 

Not good.

## 2 and 3 dimensions
```{r }
cube.3 <- cube.d %>% cmdscale(3, eig = T)
cube.2$GOF
cube.3$GOF
```

   



* Really need 3rd dimension to represent cube.


## Non-metric scaling


* Sometimes distances not meaningful *as distances*

* Only order matters: closest should be closest, farthest
farthest on map, but how much further doesn't matter.

* Non-metric scaling, aims to minimize **stress**, measure
of lack of fit.

* Example: languages. Make map based on "similarity" of number
names, without requiring that 1 is "eight times better" than 8.



## The languages


* Recall language data (from cluster analysis): 1--10, measure dissimilarity between two languages by how many number names {\em differ} in first letter:

```{r include=F}
options(width = 55)
```

     
```{r message=F, size="scriptsize"}
my_url <- "http://www.utsc.utoronto.ca/~butler/d29/languages.txt"
number.d <- read_table(my_url)
number.d
```

 



## Non-metric scaling


* Turn language dissimilarities into `dist` object

* Run through `isoMDS` from `MASS` package; works
like `cmdscale`.

* Map only reproduces {\em relative} closeness of languages.
```{r size="small"}
d <- number.d %>%
  select_if(is.numeric) %>%
  as.dist()
number.nm <- d %>% isoMDS()
names(number.nm)
```

   


* `points` for plotting, `stress` measure of fit
(lower better).




## Results


* Stress is very low (5\%, good):
```{r }
number.nm$stress
```
$ %$ %$


* Familiar process: make a data frame to plot. Use name
`dd` for data frame this time since used `d` for
distance object:
```{r }
dd <- number.nm$points %>%
  as_tibble() %>%
  mutate(lang = number.d$la)
```

   


* Make plot:
```{r }
g <- ggplot(dd, aes(x = V1, y = V2, label = lang)) +
  geom_point() + geom_text_repel()
```

   


## The languages map

```{r padova,echo=F,fig.height=4}
g
```

 


## Comments


* Tight clusters: Italian-Spanish-French, English-Danish-Norwegian.

* Dutch and German close to English group.

* Polish close to French group.

* Hungarian, Finnish distant from everything else and each other!

* Similar conclusions as from the cluster analysis.



## Shepard diagram


* Stress for languages data was 5.3\%, very low.

* How do observed dissimilarities and map distances correspond?

* For low stress, expect larger dissimilarity to go with larger
map distance, almost all the time.

* Not necessarily a linear trend since non-metric MDS works with
*order* of values.

* Actual dissimilarity on $x$-axis; map distances on $y$-axis.



## Shepard diagram for languages
```{r parma,fig.height=3.5}
Shepard(d, number.nm$points) %>%
  as_tibble() %>%
  ggplot(aes(x = x, y = y)) + geom_point()
```

 

Actual dissimilarity $x$ between higher: mapped distance $y$ from
MDS higher too. (MDS working well.)

## Cube, revisited
```{r size="small"}
cube.d <- cube %>% select(-x) %>% as.dist(cube)
cube.2 <- isoMDS(cube.d, trace = F)
cube.2$stress
cube.3 <- isoMDS(cube.d, k = 3, trace = F)
cube.3$stress
```

   



* Stress is 18\% for 2 dimensions, basically 0\% for 3.

* Three dimensions correct, two dimensions bad.

* Shepard diagrams for these:
```{r size="footnotesize"}
cube2.sh <- Shepard(cube.d, cube.2$points)
g2 <- ggplot(as.data.frame(cube2.sh), aes(x = x, y = y)) +
  geom_point()
cube3.sh <- Shepard(cube.d, cube.3$points)
g3 <- ggplot(as.data.frame(cube3.sh), aes(x = x, y = y)) +
  geom_point()
```

   



## Shepard diagram for 2-dimensional cube

```{r fig.height=3.5}
g2
```

   

Poor correspondence (not much trend).


## Shepard diagram for 3-dimensional cube
```{r fig.height=3.5}
g3
```

 
Almost perfect: all actual $x=1$ go with smallest mapped distances; almost
all $x=1.7$ go with  largest.


## Guidelines for stress values, in \%

Smaller is better:
\begin{tabular}{lp{3in}}
Stress value & Interpretation \\
\hline
Less than 5 & Excellent: no prospect of misinterpretation (rarely achieved)\\
5--10 & Good: most distances reproduced well, small prospect of false inferences\\
10--20 & Fair: usable, but some distances misleading.\\
More than 20 & Poor: may be dangerous to interpret\\
\hline
\end{tabular}



* Languages: stress in "good" range.

* Cube: 


*   2 dimensions "fair", almost "poor";

* 3 dimensions, "excellent".
 <<echo=F, warning=F>>=
 pkgs = names(sessionInfo()$otherPkgs) 
 pkgs=paste('package:', pkgs, sep = "")
 x=lapply(pkgs, detach, character.only = TRUE, unload = TRUE)
 @   




