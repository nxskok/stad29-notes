\section{Analysis of variance}
\frame{\sectionpage}

\begin{frame}[fragile]{Analysis of variance}

  \begin{itemize}
  \item Analysis of variance used with:
    \begin{itemize}
    \item counted/measured response
    \item categorical explanatory variable(s)
    \item that is, data divided into groups, and see if response significantly different among groups
    \item or, see whether knowing group membership helps to predict response.
    \end{itemize}
  \item Typically two stages:
    \begin{itemize}
    \item $F$-test to detect {\em any} differences among/due to groups
    \item if $F$-test significant, do {\em multiple comparisons} to see which groups significantly different from which.
    \item Need special multiple comparisons method because just doing (say) two-sample $t$-tests on each pair of groups gives too big a chance of finding ``significant'' differences by accident.
    \end{itemize}
  \end{itemize}
  
\end{frame}

\begin{frame}[fragile]{Packages}
  
  These:
  
<<>>=
library(tidyverse)
library(broom)
@   
  
\end{frame}

\begin{frame}[fragile]{Example: Pain threshold and hair colour}
  
  \begin{itemize}
  \item Do people with different hair colour have different abilities
    to deal with pain?
  \item Men and women of various ages divided into 4 groups by hair
    colour: light and dark blond, light and dark brown.
  \item Each subject given a pain sensitivity test resulting in pain
    threshold score: higher score is higher pain tolerance.
  \item 19 subjects altogether.
  \end{itemize}

\end{frame}

\begin{frame}[fragile]{The data}
  
  In \texttt{hairpain.txt}:
  
  \begin{multicols}{2}
\begin{verbatim}
hair pain
lightblond 62
lightblond 60
lightblond 71
lightblond 55
lightblond 48
darkblond 63
darkblond 57
darkblond 52
darkblond 41
darkblond 43
lightbrown 42
lightbrown 50
lightbrown 41
lightbrown 37
darkbrown 32
darkbrown 39
darkbrown 51
darkbrown 30
darkbrown 35
\end{verbatim}
  \end{multicols}
  
\end{frame}


\begin{frame}[fragile]{Summarizing the groups}

    
<<size="footnotesize">>=
hairpain=read_delim("hairpain.txt"," ")
hairpain %>% group_by(hair) %>%
  summarize( n=n(),
             xbar=mean(pain),
	     s=sd(pain))
@ 

Brown-haired people seem to have lower pain tolerance.
\end{frame}

\begin{frame}[fragile]{Boxplot}
  
<<tartuffo,fig.height=3.5>>=
ggplot(hairpain,aes(x=hair,y=pain))+geom_boxplot()
@   
  
\end{frame}

\begin{frame}[fragile]{Assumptions}
  
  \begin{itemize}
  \item Data should be:
    \begin{itemize}
    \item normally distributed within each group
    \item same spread for each group
    \end{itemize}

  \item \texttt{darkbrown} group has upper outlier (suggests not normal)
  \item \texttt{darkblond} group has smaller IQR than other groups.
  \item But, groups \emph{small}.
  \item Shrug shoulders and continue for moment. 
  \end{itemize}
  
\end{frame}

\begin{frame}[fragile]{Testing equality of SDs}
  
  
  \begin{itemize}
  \item   via \textbf{Levene's test} in package \texttt{car}:

<<size="small">>=
car::leveneTest(pain~hair,data=hairpain)
@   

\item No evidence (at all) of difference among group SDs.
\item Possibly because groups \emph{small}.
  \end{itemize}
  
\end{frame}

\begin{frame}[fragile]{Analysis of variance}
<<size="small">>=
hairpain.1=aov(pain~hair,data=hairpain)
summary(hairpain.1)
@   

\begin{itemize}
\item P-value small: the mean pain tolerances for the four groups are
  \emph{not} all the same.
\item Which groups differ from which, and how?
\end{itemize}
\end{frame}



\begin{frame}[fragile]{Multiple comparisons}

  \begin{itemize}
  \item Which groups differ from which? Multiple
    comparisons method. Lots.
  \item Problem: by comparing all the groups with each other, doing
    many tests, have large chance to (possibly incorrectly) reject
    $H_0:$ groups have equal means.
  \item 4 groups: 6 comparisons (1 vs 2, 1 vs 3, \ldots, 3 vs 4). 5 groups: 10
    comparisons. Thus 6 (or 10) chances to make mistake.
\item Get ``familywise error rate'' of 0.05 (whatever), no
matter how many comparisons youâ€™re doing.
\item My favourite: Tukey, or ``honestly
  significant differences'': how far apart might largest, smallest
  group means be (if actually no differences). Group means more
  different: significantly different.
  \end{itemize}
\end{frame}

\begin{frame}[fragile]{Tukey}

  \begin{itemize}
  \item \texttt{TukeyHSD:}

{\footnotesize
 
<<size="scriptsize">>=
TukeyHSD(hairpain.1)
@ %def 
}



  \end{itemize}



\end{frame}

\begin{frame}[fragile]{The old-fashioned way}
  
  \begin{itemize}
  \item List group means in order
  \item Draw lines connecting groups that are \emph{not} significantly
    different:
    
\begin{verbatim}
darkbrown lightbrown  darkblond lightblond
   37.4      42.5       51.2       59.2
   -------------------------
                        ---------------
\end{verbatim}

  \item \texttt{lightblond} significantly higher than everything
    except \texttt{darkblond} (at $\alpha=0.05$).
  \item \texttt{darkblond} in middle ground: not significantly less
    than \texttt{lightblond}, not significantly greater than
    \texttt{darkbrown} and \texttt{lightbrown}.
  \item More data might resolve this.
  \item Looks as if blond-haired people do have higher pain tolerance,
    but not completely clear.
  \end{itemize}
  
\end{frame}


\begin{frame}[fragile]{Some other multiple-comparison methods}

  \begin{itemize}
    \item Work any time you do $k$ tests at once (not just ANOVA).
      
    \item \textbf{Bonferroni}: multiply all P-values by $k$.
    \item \textbf{Holm}: multiply smallest P-value by $k$, next-smallest by
      $k-1$, etc.
    \item \texttt{False discovery rate}: multiply smallest P-value by $k/1$,
      2nd-smallest by $k/2$, \ldots, $i$-th smallest by $k/i$.
      
    \item Stop after non-rejection.
  \end{itemize}
  
\end{frame}

\begin{frame}[fragile]{Example}
  
  \begin{itemize}
  \item P-values 0.005, 0.015, 0.03, 0.06 (4 tests all done at once)
Use $\alpha=0.05$.

\item Bonferroni: 
  \begin{itemize}
  \item 
Multiply all P-values by 4 (4 tests).
\item 
Reject only 1st null.
  \end{itemize}

\item Holm: 
  \begin{itemize}
  \item 
Times smallest P-value by 4: $0.005*4=0.020<0.05$, reject.
\item 
Times next smallest by 3: $0.015*3=0.045<0.05$, reject.
\item Times next smallest by 2: $0.03*2=0.06>0.05$, do not reject. Stop.
  \end{itemize}

\item False discovery rate:
  \begin{itemize}
  \item Times smallest P-value by 4: $0.005*4=0.02<0.05$: reject.
\item Times second smallest by $4/2$: $0.015*4/2=0.03<0.05$, reject.
\item Times third smallest by $4/3$: $0.03*4/3=0.04<0.05$, reject.
\item Times fourth smallest by $4/4$: 0.06*4/4=0.06>0.05, do not reject. Stop.
  \end{itemize}
  \end{itemize}

\end{frame}

\begin{frame}[fragile]{\texttt{pairwise.t.test}}

  \begin{multicols}{2}
{\tiny
<<>>=
attach(hairpain)
pairwise.t.test(pain,hair,p.adj="none")
pairwise.t.test(pain,hair,p.adj="holm")
@   

<<>>=
pairwise.t.test(pain,hair,p.adj="fdr")
pairwise.t.test(pain,hair,p.adj="bon")
@ 
}
    
  \end{multicols}
  
\end{frame}

\begin{frame}[fragile]{Comments}
  
  \begin{itemize}
  \item P-values all adjusted upwards from ``none''.
  \item Required because 6 tests at once.
  \item Highest P-values for Bonferroni: most ``conservative''.
  \item Prefer Tukey or FDR or Holm.
  \item Tukey only applies to ANOVA, not to other cases of multiple
    testing. 
  \end{itemize}
  
\end{frame}

\begin{frame}[fragile]{Rats and vitamin B}
  
  \begin{itemize}
  \item What is the effect of dietary vitamin B on the kidney?
  \item A number of rats were randomized to receive either a
    B-supplemented diet or a regular diet.
  \item Desired to control for initial size of rats, so classified
    into size classes \texttt{lean} and \texttt{obese}.
  \item After 20 weeks, rats' kidneys weighed.
  \item Variables:
    \begin{itemize}
    \item Response: \texttt{kidneyweight} (grams).
    \item Explanatory: \texttt{diet}, \texttt{ratsize}.
    \end{itemize}
  \item Read in data:
    
<<>>=
vitaminb=read_delim("vitaminb.txt"," ")
@     
  \end{itemize}
  
\end{frame}

\begin{frame}[fragile]{The data}
  
<<>>=
vitaminb
@   
  
\end{frame}

\begin{frame}[fragile]{\emph{Grouped} boxplot}
  
<<fig.height=3.25>>=
ggplot(vitaminb,aes(x=ratsize,y=kidneyweight,
                    fill=diet))+geom_boxplot()
@   
  
\end{frame}

\begin{frame}[fragile]{What's going on?}
  
  \begin{itemize}
  \item Calculate group means:
    
<<>>=
summary = vitaminb %>% group_by(ratsize,diet) %>%
  summarize(mean=mean(kidneyweight))
summary  
@   
\item Rat size: a large and consistent effect.
\item Diet: small/no effect (compare same rat size, different
  diet).
\item Effect of rat size \emph{same} for each diet: no interaction.
  \end{itemize}

\end{frame}

\begin{frame}[fragile]{ANOVA with interaction}
  
<<>>=
vitaminb.1=aov(kidneyweight~ratsize*diet,
  data=vitaminb)
summary(vitaminb.1)
@   

Significance/nonsignificance as we expected. Note no significant
interaction (can be removed). 
  
\end{frame}

\begin{frame}[fragile]{Interaction plot}
  
  \begin{itemize}
  \item Plot mean of response variable against one of the explanatory, using
    other one as groups. Start from summary:
    
<<>>=
g=ggplot(summary,aes(x=ratsize,y=mean,
     colour=diet,group=diet))+
  geom_point()+geom_line()
@    

\item For this, have to give \emph{both} \texttt{group} and \texttt{colour}.
  \end{itemize}
  
\end{frame}

\begin{frame}[fragile]{The interaction plot}
<<fig.height=3>>=
g
@

Lines basically parallel, indicating no interaction.
\end{frame}

\begin{frame}[fragile]{Take out interaction}
  
<<size="small">>=
vitaminb.2=update(vitaminb.1,.~.-ratsize:diet)
summary(vitaminb.2)
@   

\begin{itemize}
\item No Tukey for \texttt{diet}: not significant.
\item No Tukey for \texttt{ratsize}: only two sizes, and already know
  that obese rats have larger kidneys than lean ones.
\item Bottom line: diet has no effect on kidney size once you control
  for size of rat.
\end{itemize}
  
\end{frame}



\begin{frame}[fragile]{The auto noise data}
  
  In 1973, the President of Texaco cited an automobile filter
  developed by Associated Octel Company as effective in reducing
  pollution. However, questions had been raised about the effects of
  filter silencing. He referred to the data included in the report
  (and below) as evidence
  that the silencing properties of the Octel filter were at least
  equal to those of standard silencers. 
 
<<>>=
autonoise=read_table("autonoise.txt")
@ 
  
\end{frame}

\begin{frame}[fragile]{The data}
  
<<>>=
autonoise
@   
  
\end{frame}

\begin{frame}[fragile]{Making boxplot}
  
  \begin{itemize}
  \item Make a boxplot, but have combinations of filter type and
    engine size.

  \item Use grouped boxplot again, thus:
  
<<>>=
g = autonoise %>% 
    ggplot(aes(x=size,y=noise,fill=type))+
    geom_boxplot() 

@   
  \end{itemize}
  
  
\end{frame}

\begin{frame}[fragile]{The boxplot}
<<fig.height=2.7>>=
g
@   

\begin{itemize}
\item Difference in engine noise between Octel and standard is larger for
medium engine size than for large or small.
\item Some evidence of differences in spreads (ignore for now).
\end{itemize}

\end{frame}


\begin{frame}[fragile]{ANOVA}
  
<<size="small">>=
autonoise.1=aov(noise~size*type,data=autonoise)
summary(autonoise.1)
@   

\begin{itemize}
\item The interaction is significant, as we suspected from the boxplots.
\item The within-group spreads don't look very equal, but only based
  on 6 obs each.
\end{itemize}
  
\end{frame}

\begin{frame}[fragile]{Tukey: ouch!}
  
<<size="scriptsize">>=
autonoise.2=TukeyHSD(autonoise.1)
autonoise.2$`size:type`
@ 
  
\end{frame}

\begin{frame}[fragile]{Interaction plot}
  
  \begin{itemize}
  \item This time, don't have summary of mean noise for each size-type
    combination. 
  \item One way is to compute summaries (means) first, and feed into
    \texttt{ggplot} as in vitamin B example.
  \item Or, have \texttt{ggplot} compute them for us, thus:
    
<<>>=
g=ggplot(autonoise,aes(x=size,y=noise,
    colour=type,group=type))+
  stat_summary(fun.y=mean,geom="point")+
  stat_summary(fun.y=mean,geom="line")
@     
  \end{itemize}
  
\end{frame}

\begin{frame}[fragile]{Interaction plot}
  
<<fig.height=3>>=
g
@

The lines are definitely \emph{not} parallel, showing that the effect
of \texttt{type} is different for medium-sized engines than for others.
  
\end{frame}

\begin{frame}[fragile]{If you don't like that\ldots}
  
  \ldots then compute the means first, in a pipeline:

<<fig.height=3, size="small">>=
autonoise %>% group_by(size,type) %>%
  summarize(mean_noise=mean(noise)) %>%
  ggplot(aes(x=size,y=mean_noise,group=type,
      colour=type))+geom_point()+geom_line() 
@   
    
  
\end{frame}


\begin{frame}[fragile]{Simple effects for auto noise example}
  \begin{itemize}
  \item In auto noise example, weren't interested in all comparisons
    between car size and filter type combinations.
  \item Wanted to demonstrate (lack of) difference between filter types
    \emph{for each car type}. 

  \item These are called \textbf{simple effects} of one variable
    (filter type)
    conditional on other variable (car type).

  \item To do this, pull out just the data for small cars, compare
    noise for the two filter types. Then repeat for medium and large
    cars. (Three one-way ANOVAs.)

  \end{itemize}
\end{frame}

\begin{frame}[fragile]{Do it using \texttt{dplyr} tools}
  
  \begin{itemize}
  \item Small cars:
<<>>=
autonoise %>% filter(size=="S") %>%
  aov(noise~type,data=.) %>% summary()
@     

\item No filter difference for small cars.
  

\item For Medium, change \texttt{S} to \texttt{M} and repeat.
  \end{itemize}
  
\end{frame}

\begin{frame}[fragile]{Simple effect of filter type for medium cars}
  
  {\small
<<>>=
autonoise %>% filter(size=="M") %>%
  aov(noise~type,data=.) %>% summary()
@   
}

\begin{itemize}
\item There \emph{is} an effect of filter type for medium cars. Look
  at means to investigate:
 
  {\footnotesize
<<>>=
autonoise %>% filter(size=="M") %>%
  group_by(type) %>% summarize(m=mean(noise))
@   
}


  
\end{itemize}

\end{frame}


\begin{frame}[fragile]{Medium and large cars}
  
  \begin{itemize}
\item Octel filters produce \emph{less} noise for medium cars.
\item Large cars:
<<>>=
autonoise %>% filter(size=="L") %>%
  aov(noise~type,data=.) %>% summary()
@   

\item No significant difference again.
  
  \item Or use \texttt{glance} from \texttt{broom}:

<<size="footnotesize">>=
autonoise %>% filter(size=="L") %>%
  aov(noise~type,data=.) %>% glance()
@   
    
    

  \end{itemize}


\end{frame}


\begin{frame}[fragile]{All at once, using split/apply/combine}
  
The ``split'' part:

<<>>=
autonoise %>% group_by(size) %>%
    nest()
@   

Now have \emph{three} rows, with the data frame for each size encoded
as \emph{one element} of this data frame.

\end{frame}

\begin{frame}[fragile]{Apply}
  
  \begin{itemize}
  \item   Write function to do \texttt{aov} on a
    data frame with columns \texttt{noise} and \texttt{type},
    returning P-value:
    
<<>>=
aov_pval=function(x) {
    noise.1=aov(noise~type,data=x)
    gg=glance(noise.1)
    gg$p.value
}
@     

\item Test it:
  
<<>>=
autonoise %>% filter(size=="L") %>%
  aov_pval()
@   

\item Check.

  \end{itemize}
  
\end{frame}


\begin{frame}[fragile]{Combine}
  
  \begin{itemize}
  \item Apply this function to each of the nested data frames (one per
    engine size):
    
<<>>=
autonoise %>% group_by(size) %>%
    nest() %>%
    mutate(p_val=map_dbl(data,aov_pval))
@     
\item \texttt{map\_dbl} because \texttt{aov\_pval} returns a decimal
  number (a \texttt{dbl}). Investigate what happens if you use
  \texttt{map} instead.
  \end{itemize}
  
\end{frame}

\begin{frame}[fragile]{Tidy up}
  
  \begin{itemize}
  \item The \texttt{data} column was stepping-stone to getting
    answer. Don't need it any more:
    
<<size="small">>=
simple_effects = autonoise %>% group_by(size) %>%
    nest() %>%
    mutate(p_val=map_dbl(data,aov_pval)) %>%
    select(-data)
simple_effects
@     
  \end{itemize}
  
\end{frame}

\begin{frame}[fragile]{Simultaneous tests}
  
  \begin{itemize}
  \item When testing simple effects, doing several tests at once. (In
    this case, 3.)
  \item Have to adjust P-values for this. Eg.\ Holm:
<<size="small">>=
simple_effects %>%
    arrange(p_val) %>%
    mutate(multiplier=4-row_number()) %>%
    mutate(p_val_adj=p_val*multiplier)
@     
\item No change in rejection decisions.
\item Octel filters sig.\ better in terms of noise for
  medium cars, and not sig.\ different for other sizes.
\item Octel filters never significantly worse than standard
  ones. 
  \end{itemize}
  
\end{frame}

\begin{frame}[fragile]{Confidence intervals}
  
  \begin{itemize}
  \item Perhaps better way of assessing simple effects: look at
    \emph{confidence intervals} rather than tests.
  \item Gives us sense of accuracy of estimation, and thus whether
    non-significance might be lack of power: ``absence of evidence is
    not evidence of absence''.
  \item Works here because \emph{two} filter types, using
    \texttt{t.test} for each engine type.
  \item Want to show that the Octel filter is equivalent to or better
    than the standard filter, in terms of engine noise.
  \end{itemize}
  
\end{frame}

\begin{frame}[fragile]{Equivalence and noninferiority}
  
  \begin{itemize}
  \item Known as ``equivalence testing'' in medical world. A good
    read:
    \url{http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3019319/}. Basic
    idea: decide on size of difference $\delta$ that would be considered
    ``equivalent'', and if CI entirely inside $\pm \delta$, have
    evidence in favour of equivalence.
  \item We really want to show that the Octel filters are ``no worse''
    than the standard one: that is, equivalent \emph{or better} than
    standard filters.
  \item Such a ``noninferiority test'' done by checking that
    \texttt{upper limit} of CI, new minus old, is \emph{less} than
    $\delta$. (This requires careful thinking about (i) which way
    around the difference is and (ii) whether a higher or lower value
    is better.)
  \end{itemize}
  
\end{frame}


\begin{frame}[fragile]{CI for small cars}
  
Same idea as for simple effect test:

<<>>=
autonoise %>% filter(size=="S") %>%
  t.test(noise~type,data=.) %>% .[["conf.int"]]
@ 

  
\end{frame}
 
  

\begin{frame}[fragile]{CI for medium cars}
  

<<>>=
autonoise %>% filter(size=="M") %>%
  t.test(noise~type,data=.) %>% .[["conf.int"]]
@ 
  
\end{frame}
\begin{frame}[fragile]{CI for large cars}
  

<<>>=
autonoise %>% filter(size=="L") %>%
  t.test(noise~type,data=.) %>% .[["conf.int"]]
@ 
  
\end{frame}

\begin{frame}[fragile]{Or, all at once: split/apply/combine}
  
<<size="scriptsize">>=
ci_func=function(x) {
    tt=t.test(noise~type,data=x)
    tt$conf.int
}
cis = autonoise %>%
    group_by(size) %>% nest() %>%
    mutate(ci=map(data,ci_func)) %>%
    unnest(ci)
@   

\begin{multicols}{2}
<<size="footnotesize">>=
cis
@

\begin{small}
\begin{itemize}
  
\item Function to get CI of difference in noise means for types
  of filter on input data frame
\item Group by \texttt{size}, nest (mini-df per size)
\item Calculate CI for each thing in \texttt{data} (ie.\ each
  \texttt{size}). \texttt{map}: CI is two numbers long
\item \texttt{unnest} \texttt{ci} column to see two numbers
  in each CI.
\end{itemize}
  
\end{small}


\end{multicols}
  

  
\end{frame}

\begin{frame}[fragile]{CIs and noninferiority test}
  
  \begin{itemize}
  \item Suppose we decide that a 20 dB difference would be considered
    equivalent. (I have no idea whether that is reasonable.)
    
  \item Intervals: \vspace{2ex}
   
<<size="small">>=
cis %>% mutate(hilo=rep(c("lower","upper"),3)) %>%
    spread(hilo,ci)
@     
    
%     \begin{tabular}{lrr}
%       Engine size & Lower & Upper \\
%       \hline
%       Small & --14.5 &7.9 \\
%       Medium & --30.8 &--17.6\\
%       Large & --19.3&9.3\\
%       \hline
%     \end{tabular} \vspace{2ex}

  \item In all cases, upper limit of CI is less than 20 dB. The Octel
    filters are ``noninferior'' to the standard ones.
  \item Caution: we did 3 procedures at once again. The true
    confidence level is not 95\%. (Won't worry about that here.)
  \end{itemize}
  
\end{frame}

\begin{frame}[fragile]{Contrasts in ANOVA}
  
  \begin{itemize}
  \item Sometimes, don't want to compare \emph{all} groups, only
    \emph{some} of them.
  \item Might be able to specify these comparisons ahead of time;
    other comparisons of no interest.
  \item Wasteful to do ANOVA and Tukey.
  \end{itemize}
  
\end{frame}

\begin{frame}[fragile]{Example: chainsaw kickback}
  
  \begin{itemize}
    \item From \url{http://www.ohio.edu/plantbio/staff/mccarthy/quantmet/lectures/ANOVA2.pdf}.
  \item Forest manager concerned about safety of chainsaws issued to
    field crew. 4 models of chainsaws, measure ``kickback'' (degrees
    of deflection) for 5 of each:
    
\begin{verbatim}
 A  B  C  D
-----------
42 28 57 29
17 50 45 29
24 44 48 22
39 32 41 34
43 61 54 30
\end{verbatim}
    
    \item So far, standard 1-way ANOVA: what differences are there
      among models?
  \end{itemize}
  
\end{frame}

\begin{frame}[fragile]{chainsaw kickback (2)}
  
  \begin{itemize}
    \item But: models A and D are designed to be used at home, while
      models B and C are industrial models.
    \item Suggests these comparisons of interest:
      \begin{itemize}
      \item home vs.\ industrial
      \item the two home models A vs.\ D
      \item the two industrial models B vs.\ C.
      \end{itemize}
    \item Don't need to compare \emph{all} the pairs of models.

  \end{itemize}
  
\end{frame}

\begin{frame}[fragile]{What is a contrast?}
  
  \begin{itemize}
  \item Contrast is a linear combination of group means.

  \item Notation: $\mu_A$ for (population) mean of group $A$, and so on.
  \item In example, compare two home models: $H_0: \mu_A-\mu_D=0$.
  \item Compare two industrial models: $H_0: \mu_B-\mu_C=0$.
  \item Compare average of two home models vs.\ average of two
    industrial models: $H_0: {1\over2}(\mu_A+\mu_D)-{1\over
      2}(\mu_B+\mu_C)=0$ or $H_0: 0.5\mu_A-0.5\mu_B-0.5\mu_C+0.5\mu_D=0$.
  \item Note that coefficients of contrasts add to 0, and right-hand
    side is 0.
  \end{itemize}
  
\end{frame}

\begin{frame}[fragile]{Contrasts in R}
  
  \begin{itemize}
  \item Comparing two home models A and D ($\mu_A-\mu_D=0$):
<<>>=
c.home=c(1,0,0,-1)
@     

\item Comparing two industrial models B and C ($\mu_B-\mu_C=0$):
  
<<>>=
c.industrial=c(0,1,-1,0)
@   

\item Comparing home average vs.\ industrial average ($0.5\mu_A-0.5\mu_B-0.5\mu_C+0.5\mu_D=0$):
  
<<>>=
c.home.ind=c(0.5,-0.5,-0.5,0.5)
@   
  \end{itemize}
  
\end{frame}

\begin{frame}[fragile]{Orthogonal contrasts}
  
  \begin{itemize}
  \item What happens if we multiply the contrast coefficients one by one?
<<>>=
c.home*c.industrial
c.home*c.home.ind
c.industrial*c.home.ind
@     
\item in each case, the results \textbf{add up to zero}. Such
  contrasts are called \textbf{orthogonal}.

  \end{itemize}
  
\end{frame}

\begin{frame}[fragile]{Orthogonal contrasts (2)}
  
  \begin{itemize}
\item Compare these:
<<>>=
c1=c(1,-1,0)
c1
c2=c(0,1,-1)
c2
c1*c2
@ 
Does not add up to zero, so \texttt{c1} and \texttt{c2} are \emph{not}
orthogonal.
\item Orthogonal contrasts are much easier to deal with. 

\item Can use non-orthogonal contrasts, but much more trouble (and
  beyond us).
  \end{itemize}
\end{frame}


\begin{frame}[fragile]{Starting the analysis}
  
<<size="footnotesize">>=
chain.wide=read_table("chainsaw.txt")
chain.wide
@   

  
\end{frame}

\begin{frame}[fragile]{Tidying}
  
Need all the kickbacks in \emph{one} column:

<<>>=
chain=gather(chain.wide,model,kickback,A:D,
  factor_key=T)
@ 
  
  
\end{frame}

\begin{frame}[fragile]{Starting the analysis (2)}
  
  The proper data frame, displayed in two pieces:
  
  \begin{multicols}{2}
<<>>=
chain %>% slice(1:10)
@ 

<<>>=
chain %>% slice(11:20)
@ 
  \end{multicols}
\end{frame}

\begin{frame}[fragile]{Setting up contrasts}
  
<<>>=
m=cbind(c.home,c.industrial,c.home.ind)
m
contrasts(chain$model)=m
@   

  
\end{frame}

\begin{frame}[fragile]{ANOVA as regression}

  Now run ANOVA \emph{as if regression}:

  {\scriptsize
<<>>=
chain.1=lm(kickback~model,data=chain)
summary(chain.1)
@ 
}

\end{frame}

\begin{frame}[fragile]{Conclusions}
    
<<>>=
tidy(chain.1) %>% select(term,p.value)
@     
  
  \begin{itemize}
  \item Two home models not sig.\ diff.\ (P-value 0.51)
  \item Two industrial models not sig.\ diff.\ (P-value 0.34)
  \item Home, industrial
    models \emph{are} sig.\ diff.\ (P-value 0.0032).
  \end{itemize}
  
\end{frame}

\begin{frame}[fragile]{Means by model}

  \begin{itemize}
    \item The means:
<<>>=
chain %>% group_by(model) %>%
  summarize(mean.kick=mean(kickback)) %>%
    arrange(desc(mean.kick))
@ 
\item Home models A \& D have less kickback than industrial ones B \& C.
\item Makes sense because industrial users should get training to cope
  with additional kickback.

  \end{itemize}

<<echo=F,warning=F>>=
pkgs = names(sessionInfo()$otherPkgs) 
pkgs=paste('package:', pkgs, sep = "")
x=lapply(pkgs, detach, character.only = TRUE, unload = TRUE)
@   
  
  
\end{frame}
